# -*- coding: utf-8 -*-
"""DataPreprocessingAndModelTraining

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CFE9CBcRjbI83-2z6i69HCDWCFEKc44y
"""

#importing all necessary libraries for Data Preprocessing & Visualization
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn. tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier

from google.colab import files
uploaded = files.upload()

patient_df = pd.read_csv(r"PCOS_extended_dataset.csv")

pd.set_option("display.max_columns", None)
patient_df.head()

patient_df.info()

col_list = patient_df.columns
col_list

patient_df = patient_df.dropna()

patient_df["PCOS (Y/N)"].value_counts()

#since the dataset is a bit unbalance, we delete some records with patients NOT having PCOS to make it balanced
# Filter the dataframe to get only 'PCOS' = 0
df_no = patient_df[patient_df['PCOS (Y/N)'] == 0]

# Randomly select 592 rows to delete to balance the dataset
rows_to_delete = df_no.sample(n=592, random_state=42)

# Drop these rows from the original dataframe
patient_df = patient_df.drop(rows_to_delete.index)

# Now patient_df has a balanced number of 'PCOS  (Y/N)' = 'Y' and 'N' rows

patient_df["II    beta-HCG(mIU/mL)"] = pd.to_numeric(patient_df["II    beta-HCG(mIU/mL)"], errors='coerce')
patient_df["AMH(ng/mL)"] = pd.to_numeric(patient_df["AMH(ng/mL)"], errors='coerce')
patient_df = patient_df.dropna()

patient_df.info()

numeric_df = patient_df[[" Age (yrs)", 'Weight (Kg)',
       'Height(Cm) ', 'BMI', 'Pulse rate(bpm) ',
       'RR (breaths/min)', 'Hb(g/dl)', 'Cycle length(days)',
        '  I   beta-HCG(mIU/mL)', 'II    beta-HCG(mIU/mL)', 'FSH(mIU/mL)',
       'LH(mIU/mL)', 'TSH (mIU/L)', 'AMH(ng/mL)', 'PRL(ng/mL)', 'Vit D3 (ng/mL)',
       'PRG(ng/mL)', 'RBS(mg/dl)', 'BP _Systolic (mmHg)',
       'BP _Diastolic (mmHg)', 'Follicle No. (L)', 'Follicle No. (R)',
       'Avg. F size (L) (mm)', 'Avg. F size (R) (mm)', 'Endometrium (mm)']]
numeric_df.describe()

Q1 = patient_df['Pulse rate(bpm) '].quantile(0.25)
Q3 = patient_df['Pulse rate(bpm) '].quantile(0.75)
IQR = Q3 - Q1

# Step 2: Define the bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Step 3: Replace outliers with the median value
median_value = patient_df['Pulse rate(bpm) '].median()
patient_df['Pulse rate(bpm) '] = patient_df['Pulse rate(bpm) '].apply(lambda x: median_value if x < lower_bound or x > upper_bound else x)

Q1 = patient_df['II    beta-HCG(mIU/mL)'].quantile(0.25)
Q3 = patient_df['II    beta-HCG(mIU/mL)'].quantile(0.75)
IQR = Q3 - Q1

# Step 2: Define the bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Step 3: Replace outliers with the median value
median_value = patient_df['II    beta-HCG(mIU/mL)'].median()
patient_df['II    beta-HCG(mIU/mL)'] = patient_df['II    beta-HCG(mIU/mL)'].apply(lambda x: median_value if x < lower_bound or x > upper_bound else x)

Q1 = patient_df['FSH(mIU/mL)'].quantile(0.25)
Q3 = patient_df['FSH(mIU/mL)'].quantile(0.75)
IQR = Q3 - Q1

# Step 2: Define the bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Step 3: Replace outliers with the median value
median_value = patient_df['FSH(mIU/mL)'].median()
patient_df['FSH(mIU/mL)'] = patient_df['FSH(mIU/mL)'].apply(lambda x: median_value if x < lower_bound or x > upper_bound else x)

#Replacing outlier values of LH Hormones with the median value
Q1 = patient_df['LH(mIU/mL)'].quantile(0.25)
Q3 = patient_df['LH(mIU/mL)'].quantile(0.75)
IQR = Q3 - Q1

# Step 2: Define the bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Step 3: Replace outliers with the median value
median_value = patient_df['LH(mIU/mL)'].median()
patient_df['LH(mIU/mL)'] = patient_df['LH(mIU/mL)'].apply(lambda x: median_value if x < lower_bound or x > upper_bound else x)

#Replacing outlier values of LH Hormones with the median value
Q1 = patient_df['TSH (mIU/L)'].quantile(0.25)
Q3 = patient_df['TSH (mIU/L)'].quantile(0.75)
IQR = Q3 - Q1

# Step 2: Define the bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Step 3: Replace outliers with the median value
median_value = patient_df['TSH (mIU/L)'].median()
patient_df['TSH (mIU/L)'] = patient_df['TSH (mIU/L)'].apply(lambda x: median_value if x < lower_bound or x > upper_bound else x)

#Replacing outlier values of AMH Hormones with the median value
Q1 = patient_df['AMH(ng/mL)'].quantile(0.25)
Q3 = patient_df['AMH(ng/mL)'].quantile(0.75)
IQR = Q3 - Q1

# Step 2: Define the bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Step 3: Replace outliers with the median value
median_value = patient_df['AMH(ng/mL)'].median()
patient_df['AMH(ng/mL)'] = patient_df['AMH(ng/mL)'].apply(lambda x: median_value if x < lower_bound or x > upper_bound else x)

#Replacing outlier values of PRL Hormones with the median value
Q1 = patient_df['PRL(ng/mL)'].quantile(0.25)
Q3 = patient_df['PRL(ng/mL)'].quantile(0.75)
IQR = Q3 - Q1

# Step 2: Define the bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Step 3: Replace outliers with the median value
median_value = patient_df['PRL(ng/mL)'].median()
patient_df['PRL(ng/mL)'] = patient_df['PRL(ng/mL)'].apply(lambda x: median_value if x < lower_bound or x > upper_bound else x)

#Replacing outlier values of PRG Hormones with the median value
Q1 = patient_df['PRG(ng/mL)'].quantile(0.25)
Q3 = patient_df['PRG(ng/mL)'].quantile(0.75)
IQR = Q3 - Q1

# Step 2: Define the bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Step 3: Replace outliers with the median value
median_value = patient_df['PRG(ng/mL)'].median()
patient_df['PRG(ng/mL)'] = patient_df['PRG(ng/mL)'].apply(lambda x: median_value if x < lower_bound or x > upper_bound else x)

#Replacing outlier values of RBS Hormones with the median value
Q1 = patient_df['RBS(mg/dl)'].quantile(0.25)
Q3 = patient_df['RBS(mg/dl)'].quantile(0.75)
IQR = Q3 - Q1

# Step 2: Define the bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Step 3: Replace outliers with the median value
median_value = patient_df['RBS(mg/dl)'].median()
patient_df['RBS(mg/dl)'] = patient_df['RBS(mg/dl)'].apply(lambda x: median_value if x < lower_bound or x > upper_bound else x)

#Replacing outlier values of Systolic Blood Pressure with the median value
Q1 = patient_df['BP _Systolic (mmHg)'].quantile(0.25)
Q3 = patient_df['BP _Systolic (mmHg)'].quantile(0.75)
IQR = Q3 - Q1

# Step 2: Define the bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Step 3: Replace outliers with the median value
median_value = patient_df['BP _Systolic (mmHg)'].median()
patient_df['BP _Systolic (mmHg)'] = patient_df['BP _Systolic (mmHg)'].apply(lambda x: median_value if x < lower_bound or x > upper_bound else x)

#Replacing outlier values of Diastolic Blood Pressure with the median value
Q1 = patient_df['BP _Diastolic (mmHg)'].quantile(0.25)
Q3 = patient_df['BP _Diastolic (mmHg)'].quantile(0.75)
IQR = Q3 - Q1

# Step 2: Define the bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Step 3: Replace outliers with the median value
median_value = patient_df['BP _Diastolic (mmHg)'].median()
patient_df['BP _Diastolic (mmHg)'] = patient_df['BP _Diastolic (mmHg)'].apply(lambda x: median_value if x < lower_bound or x > upper_bound else x)

# Blood Group indications
blood_group_mapping = {
    11: 'A+',
    12: 'A-',
    13: 'B+',
    14: 'B-',
    15: 'O+',
    16: 'O-',
    17: 'AB+',
    18: 'AB-'
}

# Create a figure with two subplots
fig, ax = plt.subplots(1, 2, figsize=(21, 10), sharey=True)

# Plot countplot for PCOS (Yes)
sns.countplot(data=patient_df[patient_df['PCOS (Y/N)'] == 1], x='Blood Group', ax=ax[0])
ax[0].set_title('Blood Group Distribution for PCOS (Yes)', fontsize=25)
ax[0].set_xlabel('Blood Group', fontsize=20)
ax[0].set_ylabel('Frequency', fontsize=20)
ax[0].tick_params(axis='both', labelsize=14)  # Increase tick label font size
ax[0].bar_label(ax[0].containers[0], fontsize=14, color='black')


# Plot countplot for PCOS (No)
sns.countplot(data=patient_df[patient_df['PCOS (Y/N)'] == 0], x='Blood Group', ax=ax[1])
ax[1].set_title('Blood Group Distribution for PCOS (No)', fontsize=25)
ax[1].set_xlabel('Blood Group', fontsize=20)
ax[1].set_ylabel('Frequency', fontsize=20)
ax[1].tick_params(axis='both', labelsize=14)  # Increase tick label font size
ax[1].bar_label(ax[1].containers[0], fontsize=14, color='black')



# Create a custom legend
handles = [plt.Line2D([0], [0], color='white', label=f'{value} = {key}') for key, value in blood_group_mapping.items()]
fig.legend(handles=handles, title='Blood Group Indications', loc='upper right', fontsize=15, title_fontsize = 18, bbox_to_anchor=(1.0, 0.8))

plt.tight_layout()
plt.show()

patient_df = patient_df[patient_df['Cycle(R/I)'] != 5]
patient_df.reset_index(drop=True, inplace=True)

#Visualising Correlations
correlation = patient_df[[' Age (yrs)',"BMI", "Pulse rate(bpm) ", "RR (breaths/min)", "Hb(g/dl)", "Cycle length(days)",
                      "No. of abortions", "FSH(mIU/mL)", "LH(mIU/mL)", 'BP _Systolic (mmHg)', 'BP _Diastolic (mmHg)', 'Avg. F size (R) (mm)',
                      'Endometrium (mm)', 'TSH (mIU/L)', 'AMH(ng/mL)', 'PRL(ng/mL)', 'Vit D3 (ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)', "Marraige Status (Yrs)"]].corr()

plt.figure(figsize = (20,20))
sns.heatmap(correlation, annot = True, cmap = 'Blues')
plt.title("Correlation Heatmap")
plt.show()

patient_df['PCOS'] = patient_df["PCOS (Y/N)"]
patient = patient_df.drop(["Sl. No", "Patient File No.", "Marraige Status (Yrs)", "  I   beta-HCG(mIU/mL)","PCOS (Y/N)"], axis=1)
patient.head()

patient.info()

x = patient.iloc[:, :-1]
y = patient.iloc[:, -1]

x,y

patient.head()

patient.info()

col_list = list(patient.columns)
col_list

numerical_features = [' Age (yrs)', 'Weight (Kg)','Height(Cm) ', 'BMI','Pulse rate(bpm) ', 'RR (breaths/min)', 'Hb(g/dl)','Cycle length(days)', 'No. of abortions', 'II    beta-HCG(mIU/mL)', 'FSH(mIU/mL)',
                     'LH(mIU/mL)', 'FSH/LH', 'Hip(inch)', 'Waist(inch)', 'Waist:Hip Ratio','TSH (mIU/L)', 'AMH(ng/mL)', 'PRL(ng/mL)', 'Vit D3 (ng/mL)',
                     'PRG(ng/mL)', 'RBS(mg/dl)','BP _Systolic (mmHg)','BP _Diastolic (mmHg)', 'Follicle No. (L)', 'Follicle No. (R)','Avg. F size (L) (mm)', 'Avg. F size (R) (mm)', 'Endometrium (mm)']

categorical_features = ['Blood Group','Cycle(R/I)', 'Pregnant(Y/N)', 'Weight gain(Y/N)', 'hair growth(Y/N)','Skin darkening (Y/N)', 'Hair loss(Y/N)', 'Pimples(Y/N)','Fast food (Y/N)', 'Reg.Exercise(Y/N)']

col = numerical_features + numerical_features

scaler = StandardScaler()
x_scaled_numerical = scaler.fit_transform(x[numerical_features])

from sklearn.feature_selection import SelectKBest, chi2, f_classif

f_selector = SelectKBest(f_classif, k=15)
X_numerical_selected = f_selector.fit_transform(x[numerical_features], y)


# Example for categorical features using Chi2
chi2_selector = SelectKBest(chi2, k= 'all')
X_categorical_selected = chi2_selector.fit_transform(x[categorical_features], y)

X_final = np.hstack([X_numerical_selected, X_categorical_selected])
X_final

all_features = col

numerical_selected_names = [all_features[i] for i in f_selector.get_support(indices=True)]
categorical_selected_names = [categorical_features[i] for i in chi2_selector.get_support(indices=True)]

# Combine selected feature names
selected_feature_names = numerical_selected_names + categorical_selected_names

# Create DataFrame with selected features
PCOS_final_df = pd.DataFrame(X_final, columns=selected_feature_names)

# Add target column
PCOS_final_df['PCOS'] = y.values  # Use the actual target column name

PCOS_final_df.head()

csv_filename = 'Final_PCOS_Dataset.csv'
PCOS_final_df.to_csv(csv_filename, index=False)

from google.colab import files
files.download(csv_filename)

X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=0)

classifiers = {
    'Logistic Regression' : LogisticRegression(max_iter = 7000),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(max_depth=5),
    'Support Vector Machine': SVC(),
    'Naive Bayes': GaussianNB(),
    'K-Nearest Neighbours': KNeighborsClassifier()
}

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
results = {}

for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    print("Confusion Matrix for",name,"\n", cm)
    accuracy = accuracy_score(y_test, y_pred)
    results[name]  = accuracy
    print(f'{name} Accuracy: {accuracy * 100:.2f}%')
    print(classification_report(y_test, y_pred))
    print('--------------------------------------------------------------------')

#Finding the best classifier
best_classifier = max(results, key = results.get)
print(f'Best Classifier: {best_classifier} \nAccuracy = {results[best_classifier]:.4f}')

from sklearn.metrics import roc_curve, auc

fpr, tpr, thresholds = roc_curve(y_test, y_pred)

roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color = 'magenta', lw = 2, label = f'ROC Curve (AUC Area = {roc_auc})')
plt.plot([0,1], [0,1], color = 'navy', lw = 2, linestyle = '--')
plt.xlim([0,1])
plt.ylim([0,1])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Receiver Operating Characteristic Curve")
plt.legend(loc = "lower right")
plt.grid(True)
plt.show()

#Optimising Logistic Regression
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

param_grid = {
    'C' : [0.001, 0.01, 0.1, 1, 10],
    'penalty' : ['l1', 'l2'],
    'solver' : ['liblinear','saga']
}

logistic_regression = LogisticRegression(max_iter = 7000)

grid_search = GridSearchCV(estimator = logistic_regression, param_grid = param_grid, cv = 5, scoring = 'accuracy')

grid_search.fit(X_train, y_train)

best_params = grid_search.best_params_
best_score = grid_search.best_score_

y_pred = grid_search.predict(X_test)

print("Best Parameters: ", best_params)
print("Best score: ", best_score)

best_model = grid_search.best_estimator_
print("Best Model: ", best_model)

from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix
y_pred = best_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average = 'weighted')
recall = recall_score(y_test, y_pred, average = 'weighted')
f1 = f1_score(y_test, y_pred, average = 'weighted')
conf_matrix = confusion_matrix(y_test, y_pred)

print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1: {f1:.4f}')
print("Confusion Matrix\n", conf_matrix)

"""#### Optimisng Decision Tree"""

param_grid = {
    'max_depth':[None, 3, 4, 5, 6, 7],
    'min_samples_split' : [2, 5, 7],
    'min_samples_leaf' : [1, 2, 4],
    'criterion' : ['gini', 'entropy']

}

dt = DecisionTreeClassifier(random_state = 42)
grid_search = GridSearchCV(dt, param_grid, scoring = 'accuracy', cv = 5, verbose = 1)

grid_search.fit(X_train, y_train)

best_params = grid_search.best_params_
best_score = grid_search.best_score_
best_model = grid_search.best_estimator_

print("Best Params: ", best_params)
print("Best Score: ", best_score)
print("Best Model: ", best_model)

from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix
y_pred = best_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average = 'weighted')
recall = recall_score(y_test, y_pred, average = 'weighted')
f1 = f1_score(y_test, y_pred, average = 'weighted')
conf_matrix = confusion_matrix(y_test, y_pred)

print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1: {f1:.4f}')
print("Confusion Matrix\n", conf_matrix)

from sklearn.ensemble import AdaBoostClassifier
base_dt = DecisionTreeClassifier(max_depth = 5, random_state = 42)
adaboost_clf = AdaBoostClassifier(estimator = base_dt, n_estimators = 50, random_state = 42)

adaboost_clf.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix
y_pred = best_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average = 'weighted')
recall = recall_score(y_test, y_pred, average = 'weighted')
f1 = f1_score(y_test, y_pred, average = 'weighted')
conf_matrix = confusion_matrix(y_test, y_pred)

print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1: {f1:.4f}')
print("Confusion Matrix\n", conf_matrix)

numerical_selected_indices = f_selector.get_support(indices=True)
categorical_selected_indices = chi2_selector.get_support(indices=True)

# Get selected feature names for both numerical and categorical
selected_numerical_features = [numerical_features[i] for i in numerical_selected_indices]
selected_categorical_features = [categorical_features[i] for i in categorical_selected_indices]

# Combine them into one list
selected_features = selected_numerical_features + selected_categorical_features

print("Selected Features:")
print(selected_features)

feature_importances = adaboost_clf.feature_importances_

# Create a DataFrame to display feature names and their importances together
feature_importance_df = pd.DataFrame({
    'Feature': selected_features,
    'Importance': feature_importances
})

feature_importance_df

plt.figure(figsize=(10, 10))
plt.barh(selected_features, feature_importances, color = 'navy')
plt.xlabel("Feature Importance")
plt.ylabel("Feature Name")
plt.title("Feature Importance Plot - Adaboost")
plt.grid(True)
plt.show()

from sklearn.tree import plot_tree
plt.figure(figsize =  (50,50))
plot_tree(best_model, feature_names = selected_features, filled = True, class_names = ["No PCOS", "PCOS"])
plt.title("Decision Tree Visualization")
plt.show()
